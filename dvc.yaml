stages:
  data:
    deps:
      - data/didi_wo_text/diagrams_wo_text_20200131.ndjson 
    cmd: >-
      ${run} python3 data_scripts/didi_json_to_tfrecords.py
      --data_dir ${data_dir}
      --log_level ${log_level}
    outs:
      - ${data_dir}/didi_wo_text/test
      - ${data_dir}/didi_wo_text/training
      - ${data_dir}/didi_wo_text/validation
  calculate_statistics:
    deps:
      - ${data_dir}/didi_wo_text/test
      - ${data_dir}/didi_wo_text/training
      - ${data_dir}/didi_wo_text/validation
    cmd: >-
      ${run} python3 data_scripts/calculate_data_statistics.py
      --data_dir ${data_dir}
      --log_level ${log_level}
    outs:
      - ${data_dir}/didi_wo_text/didi_wo_text-stats-origin_abs_pos.npy
  train_model:
    deps:
      - ${data_dir}/didi_wo_text/test
      - ${data_dir}/didi_wo_text/training
      - ${data_dir}/didi_wo_text/validation
      - ${data_dir}/didi_wo_text/didi_wo_text-stats-origin_abs_pos.npy
    cmd: >-
      ${run} python3 ink_training_eager_predictive.py 
      --experiment_id ${experiment_id}
      --data_dir ${data_dir}
      --experiment_dir ${experiment_dir}
      --eval_dir ${eval_dir}
      --gt_targets
      --use_start_pos
      --num_pred_inputs 32
      --stop_predictive_grad
      --pred_input_type hybrid
      --stroke_loss nll_gmm
      --n_t_samples 4
      --batch_size 128
      --affine_prob 0.3
      --resampling_factor 2
      --scale_factor 0
      --grad_clip_norm 1
      --encoder_model transformer
      --transformer_scale
      --transformer_pos_encoding
      --transformer_layers 6
      --transformer_heads 4
      --transformer_dmodel 64
      --transformer_hidden_units 256
      --transformer_dropout 0.0
      --latent_units 8
      --decoder_model t_emb
      --decoder_dropout 0.0
      --decoder_layers 4
      --decoder_hidden_units 512,512,512,512
      --predictive_model transformer
      --learning_rate_type transformer
      --p_transformer_layers 6
      --p_transformer_heads 4
      --p_transformer_dmodel 64
      --p_transformer_hidden_units 256
      --p_transformer_dropout 0.0
      --p_transformer_scale
      --embedding_loss nll_gmm
      --embedding_gmm_components 10
      --loss_predicted_embedding
      --loss_reconstructed_ink
      --position_model transformer
      --data_name didi_wo_text
      --metadata_type position
      --disable_pen_loss
      --mask_encoder_pen
